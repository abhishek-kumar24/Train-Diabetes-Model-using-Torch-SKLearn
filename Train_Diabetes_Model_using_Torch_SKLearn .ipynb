{"cells":[{"cell_type":"markdown","source":["# Introduction\n","\n","In this notebook, we will do a comprehensive analysis of the Disese Diabetes by comparing the Data of thousands of patients."],"metadata":{"id":"aX8nQeKUU8Qr"}},{"cell_type":"markdown","source":["# Import Statements"],"metadata":{"id":"gt3B_1IBVbLW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IDU82ahgUq-e"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from torch.utils.data import Dataset"]},{"cell_type":"markdown","source":["# Read & Load the dataset using Pandas"],"metadata":{"id":"nAaJlEvZVeQv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JH-H01zkUq-q"},"outputs":[],"source":["data = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQSMaLAPwUINcpluu2_4iBWsEzrXMOvu9fqmWjLC9BxxOnxPhPXSpg9TvRCQ_IvrmJ2O3x0LI_AMNaE/pub?output=csv')"]},{"cell_type":"markdown","source":["## For x: Extract the dataset from all rows & all columns except last.\n","## For y: Extract the last column.\n","## Convert both to numpy using the .values method"],"metadata":{"id":"PQzBEMN9VvRU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ORSO7LjtUq-9"},"outputs":[],"source":["x = data.iloc[:,0:-1].values\n","y_string= list(data.iloc[:,-1])"]},{"cell_type":"markdown","source":["# Lets have a look some samples from our data"],"metadata":{"id":"h7UNkVwzWEDZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iUenPYUIUq-_"},"outputs":[],"source":["print(x[:3])\n","print(y_string[:3])"]},{"cell_type":"markdown","source":["# Our neural network only understand numbers! So convert the string to labels"],"metadata":{"id":"2QhtDMMdWHR6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bejH4y-nUq_A"},"outputs":[],"source":["y_int = []\n","for string in y_string:\n","    if string == 'positive':\n","        y_int.append(1)\n","    else:\n","        y_int.append(0)"]},{"cell_type":"markdown","source":["# Now convert to an array"],"metadata":{"id":"KCShxkiaWLGK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"53YhcC3nUq_F"},"outputs":[],"source":["y = np.array(y_int, dtype = 'float64')"]},{"cell_type":"markdown","metadata":{"id":"QH_6rNzbUq_H"},"source":["# Feature Normalization. All features should have the same range of values (-1,1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gzqUPX9iUq_M"},"outputs":[],"source":["sc = StandardScaler()\n","x = sc.fit_transform(x)"]},{"cell_type":"markdown","source":["## Now we convert the arrays to PyTorch tensors\n","### We add an extra dimension to convert this array to 2D"],"metadata":{"id":"Vprt9TlSWXzE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XcwNgAhgUq_N"},"outputs":[],"source":["x = torch.tensor(x)\n","y = torch.tensor(y).unsqueeze(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_bWs9q08Uq_Q"},"outputs":[],"source":["print(x.shape)\n","print(y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TTGNfu2_Uq_R"},"outputs":[],"source":["class Dataset(Dataset):\n","\n","    def __init__(self,x,y):\n","        self.x = x\n","        self.y = y\n","        \n","    def __getitem__(self,index):\n","        # Get one item from the dataset\n","        return self.x[index], self.y[index]\n","    \n","    def __len__(self):\n","        return len(self.x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2xxoAn-UUq_S"},"outputs":[],"source":["dataset = Dataset(x,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5VDjQDG5Uq_T"},"outputs":[],"source":["len(dataset)"]},{"cell_type":"markdown","source":["# Load the data to your dataloader for batch processing and shuffling"],"metadata":{"id":"CEryaDzQWjEr"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UQY6BkZaUq_U"},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(dataset=dataset,\n","                                           batch_size=32,\n","                                           shuffle=True)"]},{"cell_type":"markdown","source":["# Let's have a look at the data loader"],"metadata":{"id":"1E_xW6MiWo6B"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ISUIPyZMUq_V"},"outputs":[],"source":["print(\"There is {} batches in the dataset\".format(len(train_loader)))\n","for (x,y) in train_loader:\n","    print(\"For one iteration (batch), there is:\")\n","    print(\"Data:    {}\".format(x.shape))\n","    print(\"Labels:  {}\".format(y.shape))\n","    break"]},{"cell_type":"markdown","metadata":{"id":"lvbVojggUq_V"},"source":["![demo](https://user-images.githubusercontent.com/30661597/60379583-246e5e80-9a68-11e9-8b7f-a4294234c201.png)"]},{"cell_type":"markdown","source":["# Now let's build the above network"],"metadata":{"id":"SJFy101UWtfg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mmaQ_yvaUq_W"},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, input_features):\n","        super(Model, self).__init__()\n","        self.fc1 = nn.Linear(input_features, 5)\n","        self.fc2 = nn.Linear(5, 4)\n","        self.fc3 = nn.Linear(4, 3)\n","        self.fc4 = nn.Linear(3, 1)\n","        self.sigmoid = nn.Sigmoid()\n","        self.tanh = nn.Tanh()\n","\n","    def forward(self, x):\n","        out = self.fc1(x)\n","        out = self.tanh(out)\n","        out = self.fc2(out)\n","        out = self.tanh(out)\n","        out = self.fc3(out)\n","        out = self.tanh(out)\n","        out = self.fc4(out)\n","        out = self.sigmoid(out)\n","        return out"]},{"cell_type":"markdown","source":[""],"metadata":{"id":"vpcUp8c7Wseq"}},{"cell_type":"markdown","metadata":{"id":"4P_T7PrqUq_Y"},"source":["### Create the network (an object of the Net class)\n","### In Binary Cross Entropy: the input and output should have the same shape \n","### size_average = True --> the losses are averaged over observations for each minibatch\n","\n","### We will use SGD with momentum with a learning rate of 0.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gqiQyn0cUq_Z"},"outputs":[],"source":["net = Model(x.shape[1])\n","criterion = torch.nn.BCELoss(size_average=True)   \n","optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)"]},{"cell_type":"markdown","source":["# Train the network "],"metadata":{"id":"qnVx9DAYXB6d"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8zc0sw8gUq_a"},"outputs":[],"source":["num_epochs = 200\n","for epoch in range(num_epochs):\n","    for inputs,labels in train_loader:\n","        inputs = inputs.float()\n","        labels = labels.float()\n","        # Feed Forward\n","        output = net(inputs)\n","        # Loss Calculation\n","        loss = criterion(output, labels)\n","        # Clear the gradient buffer (we don't want to accumulate gradients)\n","        optimizer.zero_grad()\n","        # Backpropagation \n","        loss.backward()\n","        # Weight Update: w <-- w - lr * gradient\n","        optimizer.step()\n","        \n","    #Accuracy\n","    # Since we are using a sigmoid, we will need to perform some thresholding\n","    output = (output>0.5).float()\n","    # Accuracy: (output == labels).float().sum() / output.shape[0]\n","    accuracy = (output == labels).float().mean()\n","    # Print statistics \n","    print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(epoch+1,num_epochs, loss, accuracy))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"Train_Diabetes_Model_using_Torch_SKLearn .ipynb","provenance":[],"collapsed_sections":["aX8nQeKUU8Qr","gt3B_1IBVbLW","nAaJlEvZVeQv","PQzBEMN9VvRU","h7UNkVwzWEDZ","2QhtDMMdWHR6","KCShxkiaWLGK","QH_6rNzbUq_H","Vprt9TlSWXzE","CEryaDzQWjEr","1E_xW6MiWo6B","SJFy101UWtfg","4P_T7PrqUq_Y","qnVx9DAYXB6d"]}},"nbformat":4,"nbformat_minor":0}